{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "#     surf = cv2.xfeatures2d.SURF_create()   \n",
    "#     kp, des = surf.detectAndCompute(image, None)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(image, None)\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "def match_features(des1, des2):\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)  \n",
    "    search_params = dict(checks=50)  \n",
    "    \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    match = flann.knnMatch(des1, des2, k=2) \n",
    "    return match\n",
    "\n",
    "\n",
    "def filter_matches(match, dist_threshold=0.75):\n",
    "    filtered_match = []\n",
    "    for (m, n) in match:\n",
    "        if m.distance < dist_threshold * n.distance:\n",
    "            filtered_match.append(m)\n",
    "    return filtered_match\n",
    "\n",
    "\n",
    "def estimate_homography(match, kp1, kp2):\n",
    "    src_pts = []\n",
    "    dst_pts = []    \n",
    "    for m in match:  \n",
    "        train_idx = m.trainIdx   \n",
    "        query_idx = m.queryIdx\n",
    "    \n",
    "        p1_x, p1_y = kp1[query_idx].pt\n",
    "        src_pts.append([p1_x, p1_y]) \n",
    "\n",
    "        p2_x, p2_y = kp2[train_idx].pt   \n",
    "        dst_pts.append([p2_x, p2_y])\n",
    "        \n",
    "    homography, mask = cv2.findHomography(np.array(src_pts), np.array(dst_pts), cv2.RANSAC, 5.0) \n",
    "    return homography\n",
    "\n",
    "\n",
    "def main(ref_image, template, video):\n",
    "    ref_image = cv2.imread(ref_image)  ## load gray if you need.\n",
    "    template = cv2.imread(template)  ## load gray if you need.\n",
    "    video = cv2.VideoCapture(video)\n",
    "    ref_image = cv2.resize(ref_image, template.shape[:2])\n",
    "    \n",
    "    film_h, film_w = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    film_fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    videowriter = cv2.VideoWriter(\"ar_video_2.mp4\", fourcc, film_fps, (film_w, film_h))\n",
    "    \n",
    "    i = 0\n",
    "    kp_temp, des_temp = extract_features(template)\n",
    "    while(video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        print('Processing frame {}'.format(i))\n",
    "        if ret:  ## check whethere the frame is legal, i.e., there still exists a frame\n",
    "            \n",
    "            ## TODO: homography transform, feature detection, ransanc, etc.\n",
    "            kp_frame, des_frame = extract_features(frame)\n",
    "            # display = cv2.drawKeypoints(frame, kp_frame, None)\n",
    "            match = match_features(des_temp, des_frame)\n",
    "            filtered_match = filter_matches(match)\n",
    "            H = estimate_homography(filtered_match, kp_temp, kp_frame)\n",
    "            \n",
    "            h, w, c = ref_image.shape\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    pixel = ref_image[y, x, :]\n",
    "                    u = np.array([x, y, 1])\n",
    "                    v = np.dot(H, u.T)\n",
    "                    t_x = int(round(v[0] / v[2]))\n",
    "                    t_y = int(round(v[1] / v[2]))\n",
    "                    if t_x < frame.shape[1] and t_x >= 0 and t_y < frame.shape[0] and t_y >= 0:\n",
    "                        frame[t_y-3 : t_y+3, t_x-3 : t_x+3, :] = pixel\n",
    "                    else:\n",
    "                        continue\n",
    "            \n",
    "            videowriter.write(frame)\n",
    "            i += 1\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    videowriter.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ## you should not change this part\n",
    "    ref_path = './input/me.jpg'\n",
    "    template_path = './input/marker.png'\n",
    "    video_path = './input/ar_marker.mp4'\n",
    "    main(ref_path,template_path,video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
